{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T14:33:01.323596Z",
     "start_time": "2021-04-17T14:33:01.254191Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "---------------------------------------------------\n",
    "------- Exemplos de utilização - mlcomposer -------\n",
    "---------------------------------------------------\n",
    "Script responsável por consolidar exemplos de\n",
    "aplicação relacionadas as funcionalidades presentes\n",
    "no módulo ml da biblioteca mlcomposer\n",
    "\n",
    "Sumário\n",
    "---------------------------------------------------\n",
    "1. Configuração inicial\n",
    "    1.1 Importando bibliotecas\n",
    "    1.2 Definição de variáveis do projeto\n",
    "2. Preparação da base de dados\n",
    "    2.1 Leitura das bases de treino e teste\n",
    "    2.2 Construindo pipelines de preparação\n",
    "    2.3 Aplicação dos pipelines de preparação\n",
    "3. Treinamento e avaliação de modelos\n",
    "    3.1 Estruturando objetos de modelagem\n",
    "---------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "# Autor: Thiago Panini\n",
    "# Data: 17/04/2021\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "---------------------------------------------------\n",
    "------------ 1. CONFIGURAÇÃO INICIAL --------------\n",
    "           1.1 Importando bibliotecas\n",
    "---------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "# Bibliotecas padrão\n",
    "import pandas as pd\n",
    "import os\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "# Variáveis de ambiente\n",
    "\n",
    "\n",
    "# Preparação dos dados\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Modelagem dos dados\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "------------------------------------------------------\n",
    "-------------- 1. CONFIGURAÇÃO INICIAL ---------------\n",
    "        1.2 Definição de variáveis do projeto\n",
    "------------------------------------------------------ \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "------------------------------------------------------\n",
    "----------- 2. PREPARAÇÃO DA BASE DE DADOS -----------\n",
    "        2.1 Leitura das bases de treino e teste\n",
    "------------------------------------------------------ \n",
    "\"\"\"\n",
    "\n",
    "# Leitura das bases\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Separando dados em treino e teste\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.20, random_state=42)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "------------------------------------------------------\n",
    "------- 3. TREINAMENTO E AVALIAÇÃO DE MODELOS --------\n",
    "        3.1 Estruturando objetos de modelagem\n",
    "------------------------------------------------------ \n",
    "\"\"\"\n",
    "\n",
    "# Instanciando objetos\n",
    "dtree = DecisionTreeClassifier(random_state=42)\n",
    "forest = RandomForestClassifier(random_state=42)\n",
    "svm = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "# Criando dicionário set_classifiers\n",
    "model_obj = [svm, dtree, forest]\n",
    "model_names = [type(model).__name__ for model in model_obj]\n",
    "set_classifiers = {name: {'model': obj, 'params': {}} for (name, obj) in zip(model_names, model_obj)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T14:34:01.712969Z",
     "start_time": "2021-04-17T14:34:01.687650Z"
    },
    "code_folding": [
     37,
     89
    ]
   },
   "outputs": [],
   "source": [
    "# Bibliotecas padrão\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "from math import ceil\n",
    "import os\n",
    "from os import makedirs, getcwd\n",
    "from os.path import isdir, join\n",
    "\n",
    "# Modelagem \n",
    "import joblib\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, learning_curve\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, \\\n",
    "                            f1_score, confusion_matrix, roc_curve, mean_absolute_error, \\\n",
    "                            mean_squared_error, r2_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.exceptions import NotFittedError\n",
    "import shap\n",
    "\n",
    "# Visualização\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.axes import Axes\n",
    "import seaborn as sns\n",
    "\n",
    "# AnnotateBars class (referência na classe)\n",
    "from dataclasses import dataclass\n",
    "from typing import *\n",
    "\n",
    "# Logging\n",
    "import logging\n",
    "\n",
    "\n",
    "def log_config(logger, level=logging.DEBUG, \n",
    "               log_format='%(levelname)s;%(asctime)s;%(filename)s;%(module)s;%(lineno)d;%(message)s',\n",
    "               log_filepath=os.path.join(os.getcwd(), 'exec_log/execution_log.log'),\n",
    "               flag_file_handler=False, flag_stream_handler=True, filemode='a'):\n",
    "    \"\"\"\n",
    "    Função que recebe um objeto logging e aplica configurações básicas ao mesmo\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    :param logger: objeto logger criado no escopo do módulo [type: logging.getLogger()]\n",
    "    :param level: level do objeto logger criado [type: level, default: logging.DEBUG]\n",
    "    :param log_format: formato do log a ser armazenado [type: string]\n",
    "    :param log_filepath: caminho onde o arquivo .log será armazenado [type: string, default: 'log/application_log.log']\n",
    "    :param flag_file_handler: flag para salvamento de arquivo .log [type: bool, default=False]\n",
    "    :param flag_stream_handler: flag para verbosity do log no cmd [type: bool, default=True]\n",
    "    :param filemode: tipo de escrita no arquivo de log [type: string, default: 'a' (append)]\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    :return logger: objeto logger pré-configurado\n",
    "    \"\"\"\n",
    "\n",
    "    # Setting level for the logger object\n",
    "    logger.setLevel(level)\n",
    "\n",
    "    # Creating a formatter\n",
    "    formatter = logging.Formatter(log_format, datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Creating handlers\n",
    "    if flag_file_handler:\n",
    "        log_path = '/'.join(log_filepath.split('/')[:-1])\n",
    "        if not isdir(log_path):\n",
    "            makedirs(log_path)\n",
    "\n",
    "        # Adicionando file_handler\n",
    "        file_handler = logging.FileHandler(log_filepath, mode=filemode, encoding='utf-8')\n",
    "        file_handler.setFormatter(formatter)\n",
    "        logger.addHandler(file_handler)\n",
    "\n",
    "    if flag_stream_handler:\n",
    "        # Adicionando stream_handler\n",
    "        stream_handler = logging.StreamHandler()\n",
    "        stream_handler.setFormatter(formatter)    \n",
    "        logger.addHandler(stream_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "\n",
    "# Configurando objeto de log\n",
    "logger = logging.getLogger('nb')\n",
    "logger = log_config(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T14:34:13.813177Z",
     "start_time": "2021-04-17T14:34:13.710934Z"
    },
    "code_folding": [
     8,
     15,
     174,
     241,
     325,
     398,
     450,
     536,
     614,
     692,
     713,
     739,
     773
    ]
   },
   "outputs": [],
   "source": [
    "# Classificador multiclasse\n",
    "class ClassificadorMulticlasse:\n",
    "    \"\"\"\n",
    "    Classe responsável por consolidar métodos úteis para o treinamento\n",
    "    e avaliação de modelos de classificação multiclasse em um contexto de\n",
    "    aprendizado supervisionado\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoded_target=False):\n",
    "        \"\"\"\n",
    "        Método construtor inicializa dicionário de informações dos modelos treinados\n",
    "        \"\"\"\n",
    "        self.classifiers_info = {}\n",
    "        self.encoded_target = encoded_target\n",
    "\n",
    "    def fit(self, set_classifiers, X_train, y_train, **kwargs):\n",
    "        \"\"\"\n",
    "        Método responsável por treinar cada um dos classificadores contidos no dicionário\n",
    "        set_classifiers através da aplicação das regras estabelecidas pelos argumentos do método\n",
    "\n",
    "        Parâmetros\n",
    "        ----------\n",
    "        :param set_classifiers: dicionário contendo informações dos modelos a serem treinados [type: dict]\n",
    "            set_classifiers = {\n",
    "                'model_name': {\n",
    "                    'model': __estimator__,\n",
    "                    'params': __estimator_params__\n",
    "                }\n",
    "            }\n",
    "        :param X_train: features do modelo a ser treinado [type: np.array]\n",
    "        :param y_train: array contendo variável target do modelo [type: np.array]\n",
    "        :param **kwargs: argumentos adicionais do método\n",
    "            :arg approach: indicativo de sufixo para armazenamento no atributo classifiers_info [type: string, default: '']\n",
    "            :arg random_search: flag para aplicação do RandomizedSearchCV [type: bool, default: False]\n",
    "            :arg scoring: métrica a ser otimizada pelo RandomizedSearchCV [type: string, default: 'accuracy']\n",
    "            :arg cv: K-folds utiliados na validação cruzada [type: int, default: 5]\n",
    "            :arg verbose: nível de verbosity da busca aleatória [type: int, default: -1]\n",
    "            :arg n_jobs: quantidade de jobs aplicados durante a busca dos hiperparâmetros [type: int, default: -1]\n",
    "            :arg save: flag booleano para indicar o salvamento dos arquivos em disco [type: bool, default=True]\n",
    "            :arg output_path: diretório para salvamento de objetos do modelo [type: string, default=cwd() + 'output/models']\n",
    "            :arg model_ext: extensão do objeto gerado (pkl ou joblib) - sem o ponto [type: string, default='pkl']\n",
    "\n",
    "        Retorno\n",
    "        -------\n",
    "        Este método não retorna nada além do preenchimento de informações do treinamento no atributo self.classifiers_info\n",
    "\n",
    "        Aplicação\n",
    "        ---------\n",
    "        # Instanciando objeto\n",
    "        trainer = ClassificadorBinario()\n",
    "        trainer.fit(set_classifiers, X_train_prep, y_train)\n",
    "        \"\"\"\n",
    "\n",
    "        # Referenciando argumentos adicionais\n",
    "        approach = kwargs['approach'] if 'approach' in kwargs else ''\n",
    "\n",
    "        # Iterando sobre os modelos presentes no dicionário de classificadores\n",
    "        try:\n",
    "            for model_name, model_info in set_classifiers.items():\n",
    "                # Definindo chave do classificador para o dicionário classifiers_info\n",
    "                model_key = model_name + approach\n",
    "                logger.debug(f'Treinando modelo {model_key}')\n",
    "                model = model_info['model']\n",
    "\n",
    "                # Criando dicionário vazio para armazenar dados do modelo\n",
    "                self.classifiers_info[model_key] = {}\n",
    "\n",
    "                # Validando aplicação da busca aleatória pelos melhores hiperparâmetros\n",
    "                try:\n",
    "                    if 'random_search' in kwargs and bool(kwargs['random_search']):\n",
    "                        params = model_info['params']\n",
    "                        \n",
    "                        # Retornando parâmetros em kwargs\n",
    "                        scoring = kwargs['scoring'] if 'scoring' in kwargs else 'accuracy'\n",
    "                        cv = kwargs['cv'] if 'cv' in kwargs else 5\n",
    "                        verbose = kwargs['verbose'] if 'verbose' in kwargs else -1\n",
    "                        n_jobs = kwargs['n_jobs'] if 'n_jobs' in kwargs else -1\n",
    "                        \n",
    "                        # Preparando e aplicando busca\n",
    "                        rnd_search = RandomizedSearchCV(model, params, scoring=scoring, cv=cv,\n",
    "                                                        verbose=verbose, random_state=42, n_jobs=n_jobs)\n",
    "                        logger.debug('Aplicando RandomizedSearchCV')\n",
    "                        rnd_search.fit(X_train, y_train)\n",
    "\n",
    "                        # Salvando melhor modelo no atributo classifiers_info\n",
    "                        self.classifiers_info[model_key]['estimator'] = rnd_search.best_estimator_\n",
    "                    else:\n",
    "                        # Treinando modelo sem busca e salvando no atirbuto\n",
    "                        self.classifiers_info[model_key]['estimator'] = model.fit(X_train, y_train)\n",
    "                except TypeError as te:\n",
    "                    logger.error(f'Erro ao aplicar RandomizedSearch. Exception lançada: {te}')\n",
    "                    return\n",
    "\n",
    "                # Validando salvamento de objetos pkl dos modelos\n",
    "                if 'save' in kwargs and bool(kwargs['save']):\n",
    "                    logger.debug(f'Salvando arquivo pkl do modelo {model_name} treinado')\n",
    "                    model = self.classifiers_info[model_key]['estimator']\n",
    "                    output_path = kwargs['output_path'] if 'output_path' in kwargs else os.path.join(os.getcwd(), 'output/models')\n",
    "                    model_ext = kwargs['model_ext'] if 'model_ext' in kwargs else 'pkl'\n",
    "\n",
    "                    self.save_model(model, output_path=output_path, filename=model_name.lower() + '.' + model_ext)\n",
    "\n",
    "        except AttributeError as ae:\n",
    "            logger.error(f'Erro ao treinar modelos. Exception lançada: {ae}')\n",
    "            logger.warning(f'Treinamento do(s) modelo(s) não realizado')\n",
    "\n",
    "    def compute_train_performance(self, model_name, estimator, X, y, cv=5, target_names=None):\n",
    "        \"\"\"\n",
    "        Método responsável por aplicar validação cruzada para retornar a amédia das principais métricas de avaliação\n",
    "        de um modelo de classificação. Na prática, esse método é chamado por um outro método em uma camada\n",
    "        superior da classe para medição de performance em treino e em teste\n",
    "\n",
    "        Parâmetros\n",
    "        ----------\n",
    "        :param model_name: chave identificadora do modelo contida no atributo self.classifiers_info [type: string]\n",
    "        :param estimator: estimator do modelo a ser avaliado [type: object]\n",
    "        :param X: conjunto de features do modelo contido nos dados de treino [type: np.array]\n",
    "        :param y: array contendo a variável resposta dos dados de treino do modelo [type: np.array]\n",
    "        :param cv: K-folds utiliados na validação cruzada [type: int, default: 5]\n",
    "        :param target_names: lista com referências para as classes [type: list, default=None]\n",
    "\n",
    "        Retorno\n",
    "        -------\n",
    "        :return train_performance: DataFrame contendo as métricas calculadas usando validação cruzada [type: pd.DataFrame]\n",
    "\n",
    "        Aplicação\n",
    "        ---------\n",
    "        # Instanciando e treinando modelo\n",
    "        trainer = ClassificadorBinario()\n",
    "        trainer.fit(model, X_train, y_train)\n",
    "        train_performance = trainer.compute_train_performance(model_name, estimator, X_train, y_train)\n",
    "        \"\"\"\n",
    "\n",
    "        # Computando métricas utilizando validação cruzada\n",
    "        logger.debug(f'Computando métricas do modelo {model_name} utilizando validação cruzada com {cv} K-folds')\n",
    "        try:\n",
    "            # Iniciando cronômetro e computando predições via validação cruzada\n",
    "            t0 = time.time()\n",
    "            y_pred = cross_val_predict(estimator, X, y, cv=cv)\n",
    "            \n",
    "            # Construindo classification report\n",
    "            cr = pd.DataFrame(classification_report(y, y_pred, output_dict=True, target_names=target_names)).T\n",
    "            \n",
    "            # Definindo fluxo para target codificado ou nao\n",
    "            if self.encoded_target:\n",
    "                n_classes = len(cr) - 4\n",
    "                acc = [accuracy_score(y.T[i], y_pred.T[i]) for i in range(n_classes)]\n",
    "            else:\n",
    "                n_classes = len(cr) - 3\n",
    "                acc = cr.loc['accuracy', :].values\n",
    "            \n",
    "            # Customizando classification report\n",
    "            cr_custom = cr.iloc[:n_classes, :-1]\n",
    "            cr_custom['model'] = model_name\n",
    "            cr_custom.reset_index(inplace=True)\n",
    "            cr_custom.columns = ['class'] + list(cr_custom.columns[1:])\n",
    "            \n",
    "            # Calculando acurácia para cada classe\n",
    "            cr_custom['accuracy'] = acc\n",
    "            cr_custom['approach'] = f'Treino {cv} K-folds'\n",
    "            cr_cols = ['model', 'approach', 'class', 'accuracy', 'precision', 'recall', 'f1-score']\n",
    "            train_performance = cr_custom.loc[:, cr_cols]\n",
    "\n",
    "            # Adicionando medição de tempo no DataFrame\n",
    "            t1 = time.time()\n",
    "            delta_time = t1 - t0\n",
    "            train_performance['total_time'] = round(delta_time, 3)\n",
    "            logger.info(f'Métricas computadas com sucesso nos dados de treino em {round(delta_time, 3)} segundos')\n",
    "\n",
    "            return train_performance\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f'Erro ao computar as métricas. Exception lançada: {e}')    \n",
    "\n",
    "    def compute_val_performance(self, model_name, estimator, X, y, target_names=None):\n",
    "        \"\"\"\n",
    "        Método responsável por aplicar retornar as principais métricas do model utilizando dados de validação.\n",
    "        Na prática, esse método é chamado por um outro método em uma camada superior da classe para medição \n",
    "        de performance em treino e em validação\n",
    "\n",
    "        Parâmetros\n",
    "        ----------\n",
    "        :param model_name: chave identificadora do modelo contida no atributo self.classifiers_info [type: string]\n",
    "        :param estimator: estimator do modelo a ser avaliado [type: object]\n",
    "        :param X: conjunto de features do modelo contido nos dados de teste [type: np.array]\n",
    "        :param y: array contendo a variável resposta dos dados de teste do modelo [type: np.array]\n",
    "        :param target_names: lista com referências para as classes [type: list, default=None]\n",
    "\n",
    "        Retorno\n",
    "        -------\n",
    "        :return val_performance: DataFrame contendo as métricas calculadas nos dados de validação [type: pd.DataFrame]\n",
    "\n",
    "        Aplicação\n",
    "        ---------\n",
    "        # Instanciando e treinando modelo\n",
    "        trainer = ClassificadorBinario()\n",
    "        trainer.fit(model, X_train, y_train)\n",
    "        val_performance = trainer.compute_val_performance(model_name, estimator, X_val, y_val)\n",
    "        \"\"\"\n",
    "\n",
    "        # Predicting data using the trained model and computing probabilities\n",
    "        logger.debug(f'Computando métricas do modelo {model_name} utilizando dados de teste')\n",
    "        try:\n",
    "            # Iniciando cronômetro e computando predições puras\n",
    "            t0 = time.time()\n",
    "            y_pred = estimator.predict(X)\n",
    "\n",
    "            # Construindo classification report\n",
    "            cr = pd.DataFrame(classification_report(y, y_pred, output_dict=True, target_names=target_names)).T\n",
    "            \n",
    "            # Definindo fluxo para target codificado ou nao\n",
    "            if self.encoded_target:\n",
    "                n_classes = len(cr) - 4\n",
    "                acc = [accuracy_score(y.T[i], y_pred.T[i]) for i in range(n_classes)]\n",
    "            else:\n",
    "                n_classes = len(cr) - 3\n",
    "                acc = cr.loc['accuracy', :].values\n",
    "                \n",
    "            # Customizando classification report\n",
    "            cr_custom = cr.iloc[:n_classes, :-1]\n",
    "            cr_custom['model'] = model_name\n",
    "            cr_custom.reset_index(inplace=True)\n",
    "            cr_custom.columns = ['class'] + list(cr_custom.columns[1:])\n",
    "\n",
    "            # Calculando acurácia para cada classe\n",
    "            cr_custom['accuracy'] = acc\n",
    "            cr_custom['approach'] = f'Validation set'\n",
    "            cr_cols = ['model', 'approach', 'class', 'accuracy', 'precision', 'recall', 'f1-score']\n",
    "            val_performance = cr_custom.loc[:, cr_cols]\n",
    "\n",
    "            # Adicionando medição de tempo no DataFrame\n",
    "            t1 = time.time()\n",
    "            delta_time = t1 - t0\n",
    "            val_performance['total_time'] = round(delta_time, 3)\n",
    "            logger.info(f'Métricas computadas com sucesso nos dados de validação em {round(delta_time, 3)} segundos')\n",
    "\n",
    "            return val_performance\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f'Erro ao computar as métricas. Exception lançada: {e}')    \n",
    "\n",
    "    def evaluate_performance(self, X_train, y_train, X_val, y_val, cv=5, target_names=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Método responsável por executar e retornar métricas dos classificadores em treino (média do resultado\n",
    "        da validação cruzada com cv K-fols) e teste\n",
    "        \n",
    "        Parâmetros\n",
    "        ----------\n",
    "        :param X_train: conjunto de features do modelo contido nos dados de treino [type: np.array]\n",
    "        :param y_train: array contendo a variável resposta dos dados de treino do modelo [type: np.array]\n",
    "        :param X_test: conjunto de features do modelo contido nos dados de teste [type: np.array]\n",
    "        :param y_test: array contendo a variável resposta dos dados de teste do modelo [type: np.array]\n",
    "        :param cv: K-folds utiliados na validação cruzada [type: int, default: 5]\n",
    "        :param target_names: lista com referências para as classes [type: list, default=None]\n",
    "        :param encoded_target: define a aplicação do encoding no array target [type: bool, default=True]\n",
    "        :param **kwargs: argumentos adicionais do método\n",
    "            :arg save: flag booleano para indicar o salvamento dos arquivos em disco [type: bool, default=True]\n",
    "            :arg output_path: diretório para salvamento dos arquivos [type: string, default=cwd() + 'output/metrics']\n",
    "            :arg output_filename: referência do nome do arquivo csv a ser salvo [type: string, default='metrics.csv']\n",
    "        \n",
    "        Retorno\n",
    "        -------\n",
    "        :return df_performances: DataFrame contendo as métricas calculadas em treino e teste [type: pd.DataFrame]\n",
    "\n",
    "        Aplicação\n",
    "        -----------\n",
    "        # Treinando modelo e avaliando performance em treino e teste\n",
    "        trainer = ClassificadorBinario()\n",
    "        trainer.fit(estimator, X_train, X_test)\n",
    "\n",
    "        # Definindo dicionário de controle do resultado\n",
    "        df_performance = trainer.evaluate_performance(X_train, y_train, X_val, y_val, save=True, output_path=caminho)\n",
    "        \"\"\"\n",
    "\n",
    "        # DataFrame vazio para armazenamento das métrics\n",
    "        df_performances = pd.DataFrame({})\n",
    "\n",
    "        # Iterando sobre todos os classificadores da classe\n",
    "        for model_name, model_info in self.classifiers_info.items():\n",
    "\n",
    "            # Validando se o modelo já foi treinado (dicionário model_info já terá a chave 'train_performance')\n",
    "            if 'train_performance' in model_info.keys():\n",
    "                df_performances = df_performances.append(model_info['train_performance'])\n",
    "                df_performances = df_performances.append(model_info['val_performance'])\n",
    "                continue\n",
    "\n",
    "            # Retornando modelo a ser avaliado\n",
    "            try:\n",
    "                estimator = model_info['estimator']\n",
    "            except KeyError as e:\n",
    "                logger.error(f'Erro ao retornar a chave \"estimator\" do dicionário model_info. Modelo {model_name} não treinado')\n",
    "                continue\n",
    "\n",
    "            # Computando performance em treino e em teste\n",
    "            train_performance = self.compute_train_performance(model_name, estimator, X_train, y_train, \n",
    "                                                               cv=cv, target_names=target_names)\n",
    "            val_performance = self.compute_val_performance(model_name, estimator, X_val, y_val, \n",
    "                                                           target_names=target_names)\n",
    "\n",
    "            # Adicionando os resultados ao atributo classifiers_info\n",
    "            self.classifiers_info[model_name]['train_performance'] = train_performance\n",
    "            self.classifiers_info[model_name]['val_performance'] = val_performance\n",
    "\n",
    "            # Construindo DataFrame com as métricas retornadas\n",
    "            model_performance = train_performance.append(val_performance)\n",
    "            df_performances = df_performances.append(model_performance)\n",
    "            df_performances['anomesdia_datetime'] = datetime.now()\n",
    "\n",
    "            # Salvando alguns atributos no dicionário classifiers_info para acessos futuros\n",
    "            model_data = {\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val\n",
    "            }\n",
    "            model_info['model_data'] = model_data\n",
    "\n",
    "        # Validando salvamento dos resultados\n",
    "        if 'save' in kwargs and bool(kwargs['save']):\n",
    "            output_path = kwargs['output_path'] if 'output_path' in kwargs else os.path.join(os.getcwd(), 'output/metrics')\n",
    "            output_filename = kwargs['output_filename'] if 'output_filename' in kwargs else 'metrics.csv'\n",
    "            self.save_data(df_performances, output_path=output_path, filename=output_filename)\n",
    "\n",
    "        return df_performances\n",
    "\n",
    "    def plot_metrics(self, df_metrics=None, idx_cols=['model', 'class', 'approach'], \n",
    "                 value_cols=['accuracy', 'precision', 'recall', 'f1-score'], font_scale=1.2,\n",
    "                 row='approach', col='model', margin_titles=True, x='class', y='value', hue='variable', \n",
    "                 palette='rainbow', legend_loc='center right', x_rotation=30, annot_ndec=2, \n",
    "                 annot_fontsize=8, **kwargs):\n",
    "        \"\"\"\n",
    "        Método responsável por plotar os resultados das métricas dos classificadores selecionados\n",
    "\n",
    "        Parâmetros\n",
    "        ----------\n",
    "        :param df_metrics: DataFrame específico contendo as métricas já calculadas pelo objeto [type: pd.DataFrame]\n",
    "        :param idx_cols: colunas da base de métricas a serem pivotadas \n",
    "            [type: list, default=['model', 'class', 'approach']]\n",
    "        :param value_cols: colunas da base de métricas com os valores das métricas\n",
    "            [type: list, default=['accuracy', 'precision', 'recall', 'f1-score']\n",
    "        :param font_scale: escala de fonte do FacetGrid [type: float, default=1.2]\n",
    "        :param row: referência separadora de linhas do grid [type: string, default='approach']\n",
    "        :param col: referência separadora de colunas do grid [type: string, default='model']\n",
    "        :param margin_titles: flag para plotagem dos títulos do grid [type: bool, default=True]\n",
    "        :param x: eixo x da plotagem [type: string, default='class']\n",
    "        :param y: eixo y da plotagem [type: string, default='value']\n",
    "        :param hue: separação das barras em cada plotagem [type: string, default='variable']\n",
    "        :param palette: paleta de cores utilizada [type: string, default='rainbow']\n",
    "        :param legend_loc: posicionamento da legenda [type: string, default='center right']\n",
    "        :param x_rotation: rotação dos labels no eixo x [type: int, default=30]\n",
    "        :param annot_ndec: casas decimais dos labels nas barras [type: int, default=2]\n",
    "        :param annot_fontsize: tamanho da fonte dos labels nas barras [type: int, default=8]\n",
    "\n",
    "        :param **kwargs: argumentos adicionais do método\n",
    "            :arg save: flag booleano para indicar o salvamento dos arquivos em disco [type: bool, default=True]\n",
    "            :arg output_path: diretório para salvamento dos arquivos [type: string, default=cwd() + 'output/imgs']\n",
    "            :arg output_filename: referência do nome do arquivo csv a ser salvo [type: string, default='metrics_comparison.png']\n",
    "\n",
    "        Retorno\n",
    "        -------\n",
    "        Este método não retorna nenhum parâmetro além da plotagem devidamente salva no diretório destino\n",
    "        \"\"\"\n",
    "\n",
    "        # Verificando a necessidade de calcular as métricas\n",
    "        if df_metrics is None:\n",
    "            # Retornando elementos necessários para o cálculo da performance\n",
    "            try:\n",
    "                X_train = kwargs['X_train']\n",
    "                y_train = kwargs['y_train']\n",
    "                X_val = kwargs['X_val']\n",
    "                y_val = kwargs['y_val']\n",
    "                target_names = kwargs['target_names']\n",
    "                df_metrics = self.evaluate_performance(X_train, y_train, X_val, y_val, \n",
    "                                                       target_names=target_names)\n",
    "            except Exception as e:\n",
    "                print(f'Erro ao computar as métricas. Exception lançada: {e}')\n",
    "                return\n",
    "\n",
    "        # Pivotando DataFrame de métricas de modo a facilitar a plotagem\n",
    "        metrics_melt = pd.melt(df_metrics, id_vars=idx_cols, value_vars=value_cols)\n",
    "\n",
    "        # Criando FatecGrid e plotando gráfico\n",
    "        with sns.plotting_context('notebook', font_scale=1.2):\n",
    "            g = sns.FacetGrid(metrics_melt, row=row, col=col, margin_titles=margin_titles)\n",
    "            g.map_dataframe(sns.barplot, x=x, y=y, hue=hue, palette=palette)\n",
    "\n",
    "        # Customizando figura\n",
    "        figsize = (17, 5 * len(np.unique(metrics_melt[row])))\n",
    "        g.fig.set_size_inches(figsize)\n",
    "        plt.legend(loc=legend_loc)\n",
    "        g.set_xticklabels(rotation=x_rotation)\n",
    "\n",
    "        for axs in g.axes:\n",
    "            for ax in axs:\n",
    "                AnnotateBars(n_dec=annot_ndec, color='black', font_size=annot_fontsize).vertical(ax)\n",
    "\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    def custom_confusion_matrix(self, model_name, y_true, y_pred, classes, cmap, normalize=False):\n",
    "        \"\"\"\n",
    "        Método utilizada para plotar uma matriz de confusão customizada para um único modelo da classe. Em geral,\n",
    "        esse método pode ser chamado por um método de camada superior para plotagem de matrizes para todos os\n",
    "        modelos presentes na classe\n",
    "\n",
    "        Parâmetros\n",
    "        ----------\n",
    "        :param model_name: chave identificadora do modelo contida no atributo self.classifiers_info [type: string]\n",
    "        :param y_true: array contendo a variável target do dataset [type: np.array]\n",
    "        :param y_pred: array com as predições retornadas pelo respectivo modelo [type: np.array]\n",
    "        :param classes: nomenclatura das classes da matriz [type: list]\n",
    "        :param cmap: colormap para a matriz gerada [type: matplotlib.colormap]\n",
    "        :param normalize: flag para normalizar as entradas da matriz [type: bool, default=False]\n",
    "\n",
    "        Retorno\n",
    "        -------\n",
    "        Este método não retorna nenhuma variável, além da plotagem da matriz especificada\n",
    "\n",
    "        Aplicação\n",
    "        -----------\n",
    "        Visualizar o método self.plot_confusion_matrix()\n",
    "        \"\"\"\n",
    "\n",
    "        # Retornando a matriz de confusão usando função do sklearn\n",
    "        if not self.encoded_target:\n",
    "            y_true = pd.get_dummies(y_true).values\n",
    "            y_pred = pd.get_dummies(y_pred).values\n",
    "            \n",
    "        conf_mx = confusion_matrix(y_true.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "        \n",
    "        \n",
    "        # Plotando matriz\n",
    "        plt.imshow(conf_mx, interpolation='nearest', cmap=cmap)\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "\n",
    "        # Customizando eixos\n",
    "        plt.xticks(tick_marks, classes, rotation=45)\n",
    "        plt.yticks(tick_marks, classes)\n",
    "\n",
    "        # Customizando entradas\n",
    "        fmt = '.2f' if normalize else 'd'\n",
    "        thresh = conf_mx.max() / 2.\n",
    "        for i, j in itertools.product(range(conf_mx.shape[0]), range(conf_mx.shape[1])):\n",
    "            plt.text(j, i, format(conf_mx[i, j]),\n",
    "                     horizontalalignment='center',\n",
    "                     color='white' if conf_mx[i, j] > thresh else 'black')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.title(f'{model_name}\\nConfusion Matrix', size=12)\n",
    "\n",
    "    def plot_confusion_matrix(self, classes=None, cmap=plt.cm.Blues, normalize=False, **kwargs):\n",
    "        \"\"\"\n",
    "        Método responsável por plotar gráficos de matriz de confusão usando dados de treino e teste\n",
    "        para todos os modelos presentes no dicionárion de classificadores self.classifiers_info\n",
    "\n",
    "        Parâmetros\n",
    "        ----------\n",
    "        :param cmap: colormap para a matriz gerada [type: matplotlib.colormap]\n",
    "        :param normalize: flag para normalizar as entradas da matriz [type: bool, default=False]\n",
    "        :param **kwargs: argumentos adicionais do método\n",
    "            :arg save: flag booleano para indicar o salvamento dos arquivos em disco [type: bool, default=True]\n",
    "            :arg output_path: diretório para salvamento dos arquivos [type: string, default=cwd() + 'output/imgs']\n",
    "            :arg output_filename: referência do nome do arquivo csv a ser salvo [type: string, default='confusion_matrix.png']\n",
    "\n",
    "        Retorno\n",
    "        -------\n",
    "        Este método não retorna nenhuma variável, além da plotagem da matriz especificada\n",
    "\n",
    "        Aplicação\n",
    "        ---------\n",
    "        trainer = ClassificadorBinario()\n",
    "        trainer.training_flow(set_classifiers, X_train, y_train, X_test, y_test, features)\n",
    "        trainer.plot_confusion_matrix(output_path=OUTPUT_PATH)\n",
    "        \"\"\"\n",
    "\n",
    "        # Definindo parâmetros de plotagem\n",
    "        logger.debug('Inicializando plotagem da matriz de confusão para os modelos')\n",
    "        k = 1\n",
    "        nrows = len(self.classifiers_info.keys())\n",
    "        fig = plt.figure(figsize=(14, nrows * 5.5))\n",
    "        sns.set(style='white', palette='muted', color_codes=True)\n",
    "\n",
    "        # Iterando sobre cada classificador da classe\n",
    "        for model_name, model_info in self.classifiers_info.items():\n",
    "            logger.debug(f'Retornando dados de treino e validação para o modelo {model_name}')\n",
    "            try:\n",
    "                # Retornando dados para cada modelo\n",
    "                X_train = model_info['model_data']['X_train']\n",
    "                y_train = model_info['model_data']['y_train']\n",
    "                X_val = model_info['model_data']['X_val']\n",
    "                y_val = model_info['model_data']['y_val']\n",
    "                \n",
    "                # Definindo classes para a plotagem\n",
    "                if classes is None:\n",
    "                    classes = list(range(y_train.shape[1]))\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f'Erro ao retornar dados para o modelo {model_name}. Exception lançada: {e}')\n",
    "                continue\n",
    "\n",
    "            # Realizando predições em treino (cross validation) e teste\n",
    "            logger.debug(f'Realizando predições para os dados de treino e validação ({model_name})')\n",
    "            try:\n",
    "                train_pred = cross_val_predict(model_info['estimator'], X_train, y_train, cv=5)\n",
    "                val_pred = model_info['estimator'].predict(X_val)\n",
    "            except Exception as e:\n",
    "                logger.error(f'Erro ao realizar predições para o modelo {model_name}. Exception lançada: {e}')\n",
    "                continue\n",
    "\n",
    "            logger.debug(f'Gerando matriz de confusão para o modelo {model_name}')\n",
    "            try:\n",
    "                # Plotando matriz utilizando dados de treino\n",
    "                plt.subplot(nrows, 2, k)\n",
    "                self.custom_confusion_matrix(model_name + ' Train', y_train, train_pred, classes=classes, \n",
    "                                             cmap=cmap, normalize=normalize)\n",
    "                k += 1\n",
    "\n",
    "                # Plotando matriz utilizando dados de validação\n",
    "                plt.subplot(nrows, 2, k)\n",
    "                self.custom_confusion_matrix(model_name + ' Validation', y_val, val_pred, classes=classes, \n",
    "                                             cmap=plt.cm.Greens, normalize=normalize)\n",
    "                k += 1\n",
    "                logger.info(f'Matriz de confusão gerada para o modelo {model_name}')\n",
    "            except Exception as e:\n",
    "                logger.error(f'Erro ao gerar a matriz para o modelo {model_name}. Exception lançada: {e}')\n",
    "                continue\n",
    "\n",
    "        # Alinhando figura\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Salvando imagem\n",
    "        if 'save' in kwargs and bool(kwargs['save']):\n",
    "            output_path = kwargs['output_path'] if 'output_path' in kwargs else os.path.join(os.getcwd(), 'output/imgs')\n",
    "            output_filename = kwargs['output_filename'] if 'output_filename' in kwargs else 'confusion_matrix.png'\n",
    "            self.save_fig(fig, output_path=output_path, img_name=output_filename)   \n",
    "   \n",
    "    def plot_feature_importance(self, features, top_n=20, palette='viridis', **kwargs):\n",
    "        \"\"\"\n",
    "        Método responsável por realizar uma plotagem gráfica das variáveis mais importantes pro modelo\n",
    "\n",
    "        Parâmetros\n",
    "        ----------\n",
    "        :param features: lista de features do conjunto de dados [type: list]\n",
    "        :param top_n: quantidade de features a ser considerada na plotagem [type: int, default=20]\n",
    "        :param palette: paleta de cores utilizazda na plotagem [type: string, default='viridis']\n",
    "        :param **kwargs: argumentos adicionais do método\n",
    "            :arg save: flag booleano para indicar o salvamento dos arquivos em disco [type: bool, default=True]\n",
    "            :arg output_path: diretório para salvamento dos arquivos [type: string, default=cwd() + 'output/imgs']\n",
    "            :arg output_filename: referência do nome do arquivo csv a ser salvo [type: string, default='feature_importances.png']\n",
    "\n",
    "        Retorno\n",
    "        -------\n",
    "        Este método não retorna nada além da imagem devidamente salva no diretório destino\n",
    "        \"\"\"\n",
    "\n",
    "        # Definindo parâmetros de plotagem\n",
    "        logger.debug('Inicializando plotagem das features mais importantes para os modelos')\n",
    "        feat_imp = pd.DataFrame({})\n",
    "        i = 0\n",
    "        ax_del = 0\n",
    "        nrows = len(self.classifiers_info.keys())\n",
    "        fig, axs = plt.subplots(nrows=nrows, figsize=(16, nrows * 6))\n",
    "        sns.set(style='white', palette='muted', color_codes=True)\n",
    "        \n",
    "        # Iterando sobre os modelos presentes na classe\n",
    "        for model_name, model_info in self.classifiers_info.items():\n",
    "            # Validando possibilidade de extrair a importância das features do modelo\n",
    "            logger.debug(f'Extraindo importância das features para o modelo {model_name}')\n",
    "            try:\n",
    "                importances = model_info['estimator'].feature_importances_\n",
    "            except:\n",
    "                logger.warning(f'Modelo {model_name} não possui o método feature_importances_')\n",
    "                ax_del += 1\n",
    "                continue\n",
    "            \n",
    "            # Preparando o dataset para armazenamento das informações\n",
    "            feat_imp['feature'] = features\n",
    "            feat_imp['importance'] = importances\n",
    "            feat_imp.sort_values(by='importance', ascending=False, inplace=True)\n",
    "\n",
    "            logger.debug(f'Plotando gráfico de importância das features para o modelo {model_name}')\n",
    "            try:\n",
    "                # Plotando feature importance\n",
    "                sns.barplot(x='importance', y='feature', data=feat_imp.iloc[:top_n, :], ax=axs[i], \n",
    "                            palette=palette)\n",
    "\n",
    "                # Customizando gráfico\n",
    "                axs[i].set_title(f'Features Mais Importantes: {model_name}', size=14)\n",
    "                format_spines(axs[i], right_border=False)\n",
    "                i += 1\n",
    "  \n",
    "                logger.info(f'Gráfico de importância das features plotado com sucesso para o modelo {model_name}')\n",
    "            except Exception as e:\n",
    "                logger.error(f'Erro ao gerar gráfico de importância das features para o modelo {model_name}. Exception lançada: {e}')\n",
    "                continue\n",
    "\n",
    "        # Deletando eixos sobressalentes (se aplicável)\n",
    "        if ax_del > 0:\n",
    "            logger.debug('Deletando eixos referentes a análises não realizadas')\n",
    "            try:\n",
    "                for i in range(-1, -(ax_del+1), -1):\n",
    "                    fig.delaxes(axs[i])\n",
    "            except Exception as e:\n",
    "                logger.error(f'Erro ao deletar eixo. Exception lançada: {e}')\n",
    "        \n",
    "        # Alinhando figura\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Salvando imagem\n",
    "        if 'save' in kwargs and bool(kwargs['save']):\n",
    "            output_path = kwargs['output_path'] if 'output_path' in kwargs else os.path.join(os.getcwd(), 'output/imgs')\n",
    "            output_filename = kwargs['output_filename'] if 'output_filename' in kwargs else 'feature_importances.png'\n",
    "            self.save_fig(fig, output_path=output_path, img_name=output_filename)\n",
    "    \n",
    "    def plot_shap_analysis(self, model_name, features, n_classes, figsize=(16, 10), target_names=None,\n",
    "                           **kwargs):\n",
    "        \"\"\"\n",
    "        Método responsável por plotar a análise shap pras features em um determinado modelo\n",
    "        \n",
    "        Parâmetros\n",
    "        ----------\n",
    "        :param model_name: chave de um classificador específico já treinado na classe [type: string]\n",
    "        :param features: lista de features do dataset [type: list]\n",
    "        :param n_classes: número de classes presentes no modelo [type: int]\n",
    "        :param figsize: tamanho da figure de plotagem [type: tuple, default=(16, 10)]\n",
    "        :param target_names: nomes das classes para título da plotagem [type: list, default=None]\n",
    "        :param **kwargs: argumentos adicionais do método\n",
    "            :arg save: flag booleano para indicar o salvamento dos arquivos em disco [type: bool, default=True]\n",
    "            :arg output_path: diretório para salvamento dos arquivos [type: string, default=cwd() + 'output/imgs']\n",
    "            :arg output_filename: referência do nome do arquivo csv a ser salvo [type: string, default='confusion_matrix.png']\n",
    "\n",
    "        Retorno\n",
    "        -------\n",
    "        Este método não retorna nenhum parâmetro além da análise shap especificada\n",
    "        \"\"\"\n",
    "\n",
    "        logger.debug(f'Explicando o modelo {model_name} através da análise shap')\n",
    "        try:\n",
    "            model_info = self.classifiers_info[model_name]\n",
    "            model = model_info['estimator']\n",
    "        except Exception as e:\n",
    "            logger.error(f'Classificador {model_name} não existente ou não treinado. Opções possíveis: {list(self.classifiers_info.keys())}')\n",
    "            return\n",
    "\n",
    "        logger.debug(f'Retornando parâmetros da classe para o modelo {model_name}')\n",
    "        try:\n",
    "            # Retornando parâmetros do modelo\n",
    "            X_train = model_info['model_data']['X_train']\n",
    "            X_val = model_info['model_data']['X_val']\n",
    "            df_train = pd.DataFrame(X_train, columns=features)\n",
    "            df_val = pd.DataFrame(X_val, columns=features)\n",
    "        except Exception as e:\n",
    "            logger.error(f'Erro ao retornar parâmetros para o modelo {model_name}. Exception lançada: {e}')\n",
    "\n",
    "        logger.debug(f'Criando explainer e gerando valores shap para o modelo {model_name}')\n",
    "        try:\n",
    "            explainer = shap.TreeExplainer(model, df_train)\n",
    "            shap_values = explainer.shap_values(df_val)\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                logger.warning(f'TreeExplainer não se encaixa no modelo {model_name}. Tentando LinearExplainer')\n",
    "                explainer = shap.LinearExplainer(model, df_train)\n",
    "                shap_values = explainer.shap_values(df_val, check_additivity=False)\n",
    "            except Exception as e:\n",
    "                logger.error(f'Não foi possível retornar os parâmetros para o modelo {model_name}. Exception lançada: {e}')\n",
    "                return\n",
    "        \n",
    "        # Configurando plotagem\n",
    "        nrows = ceil(n_classes / 2)\n",
    "        fig = plt.figure()\n",
    "        if not target_names:\n",
    "            target_names = [f'Classe {i}' for i in range(1, n_classes + 1)]\n",
    "        \n",
    "        # Iterando sobre as classes\n",
    "        logger.debug(f'Plotando análise shap para o modelo {model_name}')\n",
    "        for c in range(1, n_classes + 1):\n",
    "            plt.subplot(nrows, 2, c)\n",
    "            try:\n",
    "                shap.summary_plot(shap_values[c - 1], X_val, plot_type='violin', show=False, \n",
    "                                  plot_size=(15, nrows * 9))\n",
    "            except Exception as e:\n",
    "                logger.error(f'Erro ao plotar análise shap para o modelo {model_name}. Exception lançada: {e}')\n",
    "                return\n",
    "            \n",
    "            # Configurações finais e salvamento da imagem\n",
    "            plt.title(f'Shap summary plot: {target_names[c - 1]}', size=15)\n",
    "            plt.tight_layout()\n",
    "            if 'save' in kwargs and bool(kwargs['save']):\n",
    "                output_path = kwargs['output_path'] if 'output_path' in kwargs else os.path.join(os.getcwd(), 'output/imgs')\n",
    "                output_filename = kwargs['output_filename'] if 'output_filename' in kwargs else f'shap_analysis_{model_name}.png'\n",
    "                self.save_fig(fig, output_path, img_name=output_filename)\n",
    "    \n",
    "    def get_estimator(self, model_name):\n",
    "        \"\"\"\n",
    "        Método responsável por retornar o estimator de um modelo selecionado\n",
    "\n",
    "        Parâmetros\n",
    "        ----------\n",
    "        :param model_name: chave identificadora do modelo no dicionário classifiers_info da classe [type: string]\n",
    "\n",
    "        Retorno\n",
    "        -------\n",
    "        :return model: estimator do modelo já treinado\n",
    "        \"\"\"\n",
    "\n",
    "        logger.debug(f'Retornando estimator do modelo {model_name} já treinado')\n",
    "        try:\n",
    "            model_info = self.classifiers_info[model_name]\n",
    "            return model_info['estimator']\n",
    "        except Exception as e:\n",
    "            logger.error(f'Classificador {model_name} não existente ou não treinado. Opções possíveis: {list(self.classifiers_info.keys())}')\n",
    "            return\n",
    "\n",
    "    def get_metrics(self, model_name):\n",
    "        \"\"\"\n",
    "        Método responsável por retornar as métricas obtidas no treinamento\n",
    "\n",
    "        Parâmetros\n",
    "        ----------\n",
    "        None\n",
    "\n",
    "        Retorno\n",
    "        -------\n",
    "        :return model_performance: DataFrame contendo as métricas dos modelos treinados [type: pd.DataFrame]\n",
    "        \"\"\"\n",
    "\n",
    "        logger.debug(f'Retornando as métricas do modelo {model_name}')\n",
    "        try:\n",
    "            # Retornando dicionário do modelo e métricas já salvas\n",
    "            model_info = self.classifiers_info[model_name]\n",
    "            train_performance = model_info['train_performance']\n",
    "            test_performance = model_info['test_performance']\n",
    "            model_performance = train_performance.append(test_performance)\n",
    "            model_performance.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            return model_performance\n",
    "        except Exception as e:\n",
    "            logger.error(f'Erro ao retornar as métricas para o modelo {model_name}. Exception lançada: {e}')\n",
    "\n",
    "    def get_model_info(self, model_name):\n",
    "        \"\"\"\n",
    "        Método responsável por coletar as informações registradas de um determinado modelo da classe\n",
    "\n",
    "        Parâmetros\n",
    "        ----------\n",
    "        :param model_name: chave identificadora do modelo no dicionário classifiers_info da classe [type: string]\n",
    "\n",
    "        Retorno\n",
    "        -------\n",
    "        :return model_info: dicionário com informações registradas do modelo [type: dict]\n",
    "            model_info = {\n",
    "                'estimator': model,\n",
    "                'train_scores': np.array,\n",
    "                'test_scores': np.array,\n",
    "                'train_performance': pd.DataFrame,\n",
    "                'test_performance': pd.DataFrame,\n",
    "                'model_data': {\n",
    "                    'X_train': np.array,\n",
    "                    'y_train': np.array,\n",
    "                    'X_test': np.array,\n",
    "                    'y_test': np.array,\n",
    "                'feature_importances': pd.DataFrame\n",
    "                }\n",
    "            }\n",
    "        \"\"\"\n",
    "\n",
    "        logger.debug(f'Retornando informações registradas do modelo {model_name}')\n",
    "        try:\n",
    "            # Retornando dicionário do modelo\n",
    "            return self.classifiers_info[model_name]\n",
    "        except Exception as e:\n",
    "            logger.error(f'Erro ao retornar informações do modelo {model_name}. Exception lançada: {e}')\n",
    "\n",
    "    def get_classifiers_info(self):\n",
    "        \"\"\"\n",
    "        Método responsável por retornar o dicionário classifiers_info contendo todas as informações de todos os modelos\n",
    "\n",
    "        Parâmetros\n",
    "        ----------\n",
    "        None\n",
    "\n",
    "        Retorno\n",
    "        -------\n",
    "        :return classifiers_info: dicionário completo dos modelos presentes na classe\n",
    "            classifiers_info ={\n",
    "                'model_name': model_info = {\n",
    "                                'estimator': model,\n",
    "                                'train_scores': np.array,\n",
    "                                'test_scores': np.array,\n",
    "                                'train_performance': pd.DataFrame,\n",
    "                                'test_performance': pd.DataFrame,\n",
    "                                'model_data': {\n",
    "                                    'X_train': np.array,\n",
    "                                    'y_train': np.array,\n",
    "                                    'X_test': np.array,\n",
    "                                    'y_test': np.array,\n",
    "                                'feature_importances': pd.DataFrame\n",
    "                                }\n",
    "                            }\n",
    "        \"\"\"\n",
    "\n",
    "        return self.classifiers_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T14:34:19.712202Z",
     "start_time": "2021-04-17T14:34:19.492405Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG;2021-04-17 11:34:19;<ipython-input-10-4050af1f93d0>;<ipython-input-10-4050af1f93d0>;62;Treinando modelo SVC\n",
      "DEBUG;2021-04-17 11:34:19;<ipython-input-10-4050af1f93d0>;<ipython-input-10-4050af1f93d0>;62;Treinando modelo DecisionTreeClassifier\n",
      "DEBUG;2021-04-17 11:34:19;<ipython-input-10-4050af1f93d0>;<ipython-input-10-4050af1f93d0>;62;Treinando modelo RandomForestClassifier\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "------------------------------------------------------\n",
    "------- 3. TREINAMENTO E AVALIAÇÃO DE MODELOS --------\n",
    "  3.2 Encapsulando etapa de treinamento e avaliação\n",
    "------------------------------------------------------ \n",
    "\"\"\"\n",
    "\n",
    "# Instanciando novo objeto\n",
    "trainer = ClassificadorMulticlasse()\n",
    "\n",
    "# Treinando modelo\n",
    "trainer.fit(set_classifiers, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T14:38:01.580527Z",
     "start_time": "2021-04-17T14:38:01.514305Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG;2021-04-17 11:38:01;<ipython-input-10-4050af1f93d0>;<ipython-input-10-4050af1f93d0>;706;Retornando estimator do modelo DecisionTreeClassifier já treinado\n"
     ]
    }
   ],
   "source": [
    "# Testando predições\n",
    "model_name = 'DecisionTreeClassifier'\n",
    "model = trainer.get_estimator(model_name)\n",
    "y_pred = cross_val_predict(model, X_train, y_train, cv=5)\n",
    "cr = pd.DataFrame(classification_report(y_train, y_pred, output_dict=True, target_names=None)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T14:38:03.888532Z",
     "start_time": "2021-04-17T14:38:03.827653Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.941667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.941938</td>\n",
       "      <td>0.941422</td>\n",
       "      <td>0.941585</td>\n",
       "      <td>120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.941802</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.941639</td>\n",
       "      <td>120.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              1.000000  1.000000  1.000000   40.000000\n",
       "1              0.904762  0.926829  0.915663   41.000000\n",
       "2              0.921053  0.897436  0.909091   39.000000\n",
       "accuracy       0.941667  0.941667  0.941667    0.941667\n",
       "macro avg      0.941938  0.941422  0.941585  120.000000\n",
       "weighted avg   0.941802  0.941667  0.941639  120.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T14:43:50.989454Z",
     "start_time": "2021-04-17T14:43:50.960498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9416666666666667, 0.9416666666666667, 0.9416666666666667]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = len(cr) - 3\n",
    "acc = cr.loc['accuracy', :].values\n",
    "acc = [acc[0]] * n_classes\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T14:43:52.327719Z",
     "start_time": "2021-04-17T14:43:52.315473Z"
    }
   },
   "outputs": [],
   "source": [
    "# Customizando classification report\n",
    "cr_custom = cr.iloc[:n_classes, :-1]\n",
    "cr_custom['model'] = model_name\n",
    "cr_custom.reset_index(inplace=True)\n",
    "cr_custom.columns = ['class'] + list(cr_custom.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T14:43:52.850730Z",
     "start_time": "2021-04-17T14:43:52.818367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class  precision    recall  f1-score                   model\n",
       "0     0   1.000000  1.000000  1.000000  DecisionTreeClassifier\n",
       "1     1   0.904762  0.926829  0.915663  DecisionTreeClassifier\n",
       "2     2   0.921053  0.897436  0.909091  DecisionTreeClassifier"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T14:44:06.117482Z",
     "start_time": "2021-04-17T14:44:06.093364Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculando acurácia para cada classe\n",
    "cr_custom['accuracy'] = acc\n",
    "cr_custom['approach'] = f'Treino 5 K-folds'\n",
    "cr_cols = ['model', 'approach', 'class', 'accuracy', 'precision', 'recall', 'f1-score']\n",
    "train_performance = cr_custom.loc[:, cr_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T14:44:10.890991Z",
     "start_time": "2021-04-17T14:44:10.862821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>approach</th>\n",
       "      <th>class</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Treino 5 K-folds</td>\n",
       "      <td>0</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Treino 5 K-folds</td>\n",
       "      <td>1</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.915663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Treino 5 K-folds</td>\n",
       "      <td>2</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model          approach class  accuracy  precision  \\\n",
       "0  DecisionTreeClassifier  Treino 5 K-folds     0  0.941667   1.000000   \n",
       "1  DecisionTreeClassifier  Treino 5 K-folds     1  0.941667   0.904762   \n",
       "2  DecisionTreeClassifier  Treino 5 K-folds     2  0.941667   0.921053   \n",
       "\n",
       "     recall  f1-score  \n",
       "0  1.000000  1.000000  \n",
       "1  0.926829  0.915663  \n",
       "2  0.897436  0.909091  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
